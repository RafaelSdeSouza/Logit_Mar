K          <- ncol(X)                   # Number of Predictors including the intercept
y          <- as.numeric(data_n2$bpt)-1 # Response variable (0/1)
n          <- length(y)                 # Sample size
# Grid of values for prediction
gx <- seq(1.75*min(X[,2]),1.75*max(X[,2]),length.out=250)
Mx <- seq(1.75*min(X[,2]),1.75*max(X[,3]),length.out=250)
Rx <- seq(1.75*min(X[,2]),1.75*max(X[,4]),length.out=250)
sfrx <- seq(1.75*min(X[,2]),1.75*max(X[,5]),length.out=250)
grx <-  seq(1.75*min(X[,2]),1.75*max(X[,6]),length.out=250)
jags.data  <- list(Y= y,N = n,X=X,b0 = rep(0,K),B0=diag(1e-4,K),gx=gx,Mx=Mx,
Rx=Rx,sfrx=sfrx, grx = grx )
# b0 and B0 are the mean vector and the inverse of the covariance matrix of prior distribution of the regression coefficients
### Prior Specification and Likelihood function
model<-"model{
#1. Priors
#a.Normal
beta~dmnorm(b0,B0)
#b.Jefreys priors for sparseness
#for(j in 1:K)   {
#lnTau[j] ~ dunif(-50, 50)
#TauM[j] <- exp(lnTau[j])
#beta[j] ~ dnorm(0, TauM[j])
#Ind[j] <- step(abs(beta[j]) - 0.05)
#}
#c.LASSO
#for(j in 1:K){
#beta[j]~ddexp(0,tau)
#}
#c1.prior for tau
#tau <-pow(sdBeta,-1)
#sdBeta ~ dgamma(0.01,0.01)
#2. Likelihood
for(i in 1:N){
Y[i] ~ dbern(pi[i])
logit(pi[i]) <-  eta[i]
eta[i] <- inprod(beta[], X[i,])
}
#3.Probability for each variable
# E galaxies
for(l in 1:250){
logit(pgx[l])<-beta[1]+beta[2]*gx[l]
logit(pMx[l])<-beta[1]+beta[3]*Mx[l]
logit(pRx[l])<-beta[1]+beta[4]*Rx[l]
logit(psfrx[l])<-beta[1]+beta[5]*sfrx[l]
logit(pgrx[l])<-beta[1]+beta[6]*grx[l]
# S galaxies
logit(pgxS[l])<-beta[1]+beta[2]*gx[l]+beta[7]
logit(pMxS[l])<-beta[1]+beta[3]*Mx[l]+beta[7]
logit(pRxS[l])<-beta[1]+beta[4]*Rx[l]+beta[7]
logit(psfrS[l])<-beta[1]+beta[5]*sfrx[l]+beta[7]
logit(pgrS[l])<-beta[1]+beta[6]*grx[l]+beta[7]
}
}"
params <- c("beta","pi","pgx","pMx","pRx","psfrx","pgrx",
"pgxS","pMxS","pRxS","psfrS","pgrS")        # Monitor these parameters.
inits0  <- function () {list(beta = rnorm(K, 0, 0.01))} # A function to generat initial values for mcmc
inits1=inits0();inits2=inits0();inits3=inits0()         # Generate initial values for three chains
# Run mcmc
bin    = 10^4   # burn-in samples
ad     = 10^4   # Number of adaptive samples
s      = 3*10^4 # Number of samples for each chain
nc     = 3      # Number of mcmc
th     = 10     # Thinning value
jags.logit  <- run.jags(method="rjparallel",data = jags.data,inits = list(inits1,inits2,inits3),model=model,
n.chains = nc,adapt=ad,monitor=c(params),burnin=bin,thin=th,sample=s,summarise=FALSE,plots=FALSE)
### Prior Specification and Likelihood function
model<-"model{
#1. Priors
#a.Normal
beta~dmnorm(b0,B0)
#b.Jefreys priors for sparseness
#for(j in 1:K)   {
#lnTau[j] ~ dunif(-50, 50)
#TauM[j] <- exp(lnTau[j])
#beta[j] ~ dnorm(0, TauM[j])
#Ind[j] <- step(abs(beta[j]) - 0.05)
#}
#c.LASSO
#for(j in 1:K){
#beta[j]~ddexp(0,tau)
#}
#c1.prior for tau
#tau <-pow(sdBeta,-1)
#sdBeta ~ dgamma(0.01,0.01)
#2. Likelihood
for(i in 1:N){
Y[i] ~ dbern(pi[i])
logit(pi[i]) <-  eta[i]
eta[i] <- inprod(beta[galtype[i]], X[i,])
}
#3.Probability for each variable
# E galaxies
for(l in 1:250){
logit(pgx[l])<-beta[1]+beta[2]*gx[l]
logit(pMx[l])<-beta[1]+beta[3]*Mx[l]
logit(pRx[l])<-beta[1]+beta[4]*Rx[l]
logit(psfrx[l])<-beta[1]+beta[5]*sfrx[l]
logit(pgrx[l])<-beta[1]+beta[6]*grx[l]
# S galaxies
logit(pgxS[l])<-beta[1]+beta[2]*gx[l]+beta[7]
logit(pMxS[l])<-beta[1]+beta[3]*Mx[l]+beta[7]
logit(pRxS[l])<-beta[1]+beta[4]*Rx[l]+beta[7]
logit(psfrS[l])<-beta[1]+beta[5]*sfrx[l]+beta[7]
logit(pgrS[l])<-beta[1]+beta[6]*grx[l]+beta[7]
}
}"
params <- c("beta","pi","pgx","pMx","pRx","psfrx","pgrx",
"pgxS","pMxS","pRxS","psfrS","pgrS")        # Monitor these parameters.
inits0  <- function () {list(beta = rnorm(K, 0, 0.01))} # A function to generat initial values for mcmc
inits1=inits0();inits2=inits0();inits3=inits0()         # Generate initial values for three chains
# Run mcmc
bin    = 10^4   # burn-in samples
ad     = 10^4   # Number of adaptive samples
s      = 3*10^4 # Number of samples for each chain
nc     = 3      # Number of mcmc
th     = 10     # Thinning value
jags.logit  <- run.jags(method="rjparallel",data = jags.data,inits = list(inits1,inits2,inits3),model=model,
n.chains = nc,adapt=ad,monitor=c(params),burnin=bin,thin=th,sample=s,summarise=FALSE,plots=FALSE)
setwd("~/Dropbox/artigos/Meusartigos/IAA-WGC/Github/Logit_Mar/script")
setwd("~/Dropbox/artigos/Meusartigos/IAA-WGC/Github/Logit_Mar/script")
# JAGS Code with Adaptive Shrinkage
#  Required libraries
library(rjags);library(ggmcmc);library(ggplot2);library(ggthemes);library(pander);library(Cairo);library(MASS);library(parallel)
library(scales);library(plyr);require(gdata);require(runjags);require(gdata);require(caret);require(pROC);require(plyr)
cl       <- makeCluster(3) # For parallel computing
# Read and format data
data     <- read.csv("..//data/sample_CRP02_sub.csv",header=TRUE,na.strings="")
data_cut <- data[,c("bpt","lgm_tot_p50","logM200_L","RprojLW_Rvir","sfr_tot_p50","color_gr","zoo")]
data2    <- na.omit(data_cut)
data2    <- data2[data2$lgm_tot_p50>0,]
data2    <- data2[which(data2$logM200_L>0),]
data2    <- data2[which(data2$RprojLW_Rvir>=0),]
data2    <- data2[which(data2$sfr_tot_p50>=-100),]
# Standardized variables
data2<-data.frame(bpt=data2$bpt,as.data.frame(scale(data2[,2:6])),zoo=data2$zoo)
#trainIndex <- sample(1:nrow(data2),2000)
#data3      <- data2[trainIndex,]
data3    <-data2
#data3    <- subset(data3, bpt!="LINER")    # remove Liners
data3$bpt  <- revalue(data3$bpt,c("Star Forming"="0","Composite"="0",
"LINER"="1","Seyfert/LINER"="1","Star Fo"="0",
"Seyfert"="1","BLANK"="0"))
data_n     <- data3
#data_n2    <- subset(data_n, zoo=="E" | zoo == "S")
data_n2    <- subset(data_n, zoo=="E")
#galtype    <- match(data_n2$zoo,c("E", "S"))
#galtype    <- galtype-1                 # 0 = E and 1 = S
X          <- model.matrix( ~ lgm_tot_p50 + logM200_L + RprojLW_Rvir +
sfr_tot_p50 + color_gr, data = data_n2) # Predictors
K          <- ncol(X)                   # Number of Predictors including the intercept
y          <- as.numeric(data_n2$bpt)-1 # Response variable (0/1)
n          <- length(y)                 # Sample size
# Grid of values for prediction
gx <- seq(1.75*min(X[,2]),1.75*max(X[,2]),length.out=250)
Mx <- seq(1.75*min(X[,2]),1.75*max(X[,3]),length.out=250)
Rx <- seq(1.75*min(X[,2]),1.75*max(X[,4]),length.out=250)
sfrx <- seq(1.75*min(X[,2]),1.75*max(X[,5]),length.out=250)
grx <-  seq(1.75*min(X[,2]),1.75*max(X[,6]),length.out=250)
jags.data  <- list(Y= y,N = n,X=X,b0 = rep(0,K),B0=diag(1e-4,K),gx=gx,Mx=Mx,
Rx=Rx,sfrx=sfrx, grx = grx )
# b0 and B0 are the mean vector and the inverse of the covariance matrix of prior distribution of the regression coefficients
### Prior Specification and Likelihood function
model<-"model{
#1. Priors
#a.Normal
beta~dmnorm(b0,B0)
#b.Jefreys priors for sparseness
#for(j in 1:K)   {
#lnTau[j] ~ dunif(-50, 50)
#TauM[j] <- exp(lnTau[j])
#beta[j] ~ dnorm(0, TauM[j])
#Ind[j] <- step(abs(beta[j]) - 0.05)
#}
#c.LASSO
#for(j in 1:K){
#beta[j]~ddexp(0,tau)
#}
#c1.prior for tau
#tau <-pow(sdBeta,-1)
#sdBeta ~ dgamma(0.01,0.01)
#2. Likelihood
for(i in 1:N){
Y[i] ~ dbern(pi[i])
logit(pi[i]) <-  eta[i]
eta[i] <- inprod(beta[], X[i,])
}
#3.Probability for each variable
# E galaxies
for(l in 1:250){
logit(pgx[l])<-beta[1]+beta[2]*gx[l]
logit(pMx[l])<-beta[1]+beta[3]*Mx[l]
logit(pRx[l])<-beta[1]+beta[4]*Rx[l]
logit(psfrx[l])<-beta[1]+beta[5]*sfrx[l]
logit(pgrx[l])<-beta[1]+beta[6]*grx[l]
# S galaxies
#logit(pgxS[l])<-beta[1]+beta[2]*gx[l]+beta[7]
#logit(pMxS[l])<-beta[1]+beta[3]*Mx[l]+beta[7]
#logit(pRxS[l])<-beta[1]+beta[4]*Rx[l]+beta[7]
#logit(psfrS[l])<-beta[1]+beta[5]*sfrx[l]+beta[7]
#logit(pgrS[l])<-beta[1]+beta[6]*grx[l]+beta[7]
}
}"
params <- c("beta","pi","pgx","pMx","pRx","psfrx","pgrx")        # Monitor these parameters.
inits0  <- function () {list(beta = rnorm(K, 0, 0.01))} # A function to generat initial values for mcmc
inits1=inits0();inits2=inits0();inits3=inits0()         # Generate initial values for three chains
# Run mcmc
bin    = 10^4   # burn-in samples
ad     = 10^4   # Number of adaptive samples
s      = 3*10^4 # Number of samples for each chain
nc     = 3      # Number of mcmc
th     = 10     # Thinning value
jags.logit  <- run.jags(method="rjparallel",data = jags.data,inits = list(inits1,inits2,inits3),model=model,
n.chains = nc,adapt=ad,monitor=c(params),burnin=bin,thin=th,sample=s,summarise=FALSE,plots=FALSE)
jagssamples <- as.mcmc.list(jags.logit)
labels<-c(expression(beta[0]),expression(beta[1]),expression(beta[2]),
expression(beta[3]),expression(beta[4]),expression(beta[5]),expression(beta[6]))
L.radon.intercepts <- data.frame(
Parameter=paste("beta[", seq(1:7), "]", sep=""),
Label=labels)
head(L.radon.intercepts)
#"lgm_tot_p50","logM200_L","RprojLW_Rvir","sfr_tot_p50","color_gr","zoo"
G1<-ggs(jagssamples,family="beta")
plotbeta<-ggs_caterpillar(G1)+theme_hc()+
theme(legend.position="none",plot.title = element_text(hjust=0.5),
axis.title.y=element_text(vjust=0.75),axis.text.x=element_text(size=18),
axis.text.y=element_text(size=18),
strip.text.x=element_text(size=25),
axis.title.x=element_text(vjust=-0.25),
text = element_text(size=20),axis.title.x=element_text(size=rel(1)))+
geom_vline(xintercept=0,linetype="dashed",colour=c("#034e7b")) +
aes(color="#034e7b")+ylab("")+
scale_y_discrete(breaks=c("beta[1]", "beta[2]", "beta[3]","beta[4]","beta[5]","beta[6]","beta[7]"),
labels=c(expression(beta[1]),expression(beta[2]),expression(beta[3]),
expression(beta[4]),expression(beta[5]),expression(beta[6]),expression(beta[7])))
CairoPDF("betas_E.pdf",width = 5, height = 6)
plotbeta
dev.off()
plotbeta<-ggs_caterpillar(G1)+theme_hc()+
theme(legend.position="none",plot.title = element_text(hjust=0.5),
axis.title.y=element_text(vjust=0.75),axis.text.x=element_text(size=18),
axis.text.y=element_text(size=18),
strip.text.x=element_text(size=25),
axis.title.x=element_text(vjust=-0.25),
text = element_text(size=20),axis.title.x=element_text(size=rel(1)))+
geom_vline(xintercept=0,linetype="dashed",colour=c("#034e7b")) +
aes(color="#034e7b")+ylab("")+
scale_y_discrete(breaks=c("beta[1]", "beta[2]", "beta[3]","beta[4]","beta[5]","beta[6]","beta[7]"),
labels=c(expression(beta[1]),expression(beta[2]),expression(beta[3]),
expression(beta[4]),expression(beta[5]),expression(beta[6]),expression(beta[7])))
library(Cairo)
CairoPDF("betas_E.pdf",width = 5, height = 6)
plotbeta
dev.off()
cairo_pdf("betas_E.pdf",width = 5, height = 6)
plotbeta
dev.off()
install.packages("cairoDevice")
install.packages("Cairo")
CairoPDF("betas_E.pdf",width = 5, height = 6)
plotbeta
dev.off()
CairoPDF("..//figures/betas_E.pdf",width = 5, height = 6)
plotbeta
dev.off()
cairo_pdf("..//figures/betas_E.pdf",width = 5, height = 6)
plotbeta
dev.off()
detach("package:Cairo", unload=TRUE)
library("Cairo", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
CairoPDF("..//figures/betas_E.pdf",width = 5, height = 6)
plotbeta
dev.off()
plotbeta
cairo_pdf("..//figures/betas_E.pdf",width = 5, height = 6)
plotbeta
dev.off()
plotbeta
cairo_pdf("..//figures/betas_E.pdf",width = 5, height = 6)
plotbeta
dev.off()
cairo_pdf("..//figures/betas_E.pdf",width = 5, height = 6)
plotbeta
dev.off()
CairoPDF("..//figures/betas_E.pdf",width = 5, height = 6)
plotbeta
dev.off()
installed.packages("Cairo", type="source",dependencies=TRUE)
installed.packages("Cairo", type=source,dependencies=TRUE)
installed.packages(Cairo, type=source,dependencies=TRUE)
install.packages(Cairo, type=source,dependencies=TRUE)
install.packages("Cairo", type=source,dependencies=TRUE)
install.packages("Cairo", type = source, dependencies = TRUE)
install.packages("Cairo", type = "source", dependencies = TRUE)
install.packages("Cairo", type = "source", dependencies = TRUE)
plotbeta
plot(beta)
gelman.diag(beta)
gelman.plot(beta)
geweke.diag(beta)
geweke.plot(beta)
autocorr.plot(beta)
beta     <- as.mcmc.list(jags.logit,vars="beta")
pi       <- as.mcmc.list(jags.logit,vars="pi")
pgx     <- as.mcmc.list(jags.logit,vars="pgx")
# Trace plots and diagnostic analysis to investigate convregence
plot(beta)
gelman.diag(beta)
gelman.plot(beta)
geweke.diag(beta)
geweke.plot(beta)
model<-"model{
#1. Priors
#a.Normal
#beta~dmnorm(b0,B0)
#b.Jefreys priors for sparseness
for(j in 1:K)   {
lnTau[j] ~ dunif(-50, 50)
TauM[j] <- exp(lnTau[j])
beta[j] ~ dnorm(0, TauM[j])
Ind[j] <- step(abs(beta[j]) - 0.05)
}
#c.LASSO
#for(j in 1:K){
#beta[j]~ddexp(0,tau)
#}
#c1.prior for tau
#tau <-pow(sdBeta,-1)
#sdBeta ~ dgamma(0.01,0.01)
#2. Likelihood
for(i in 1:N){
Y[i] ~ dbern(pi[i])
logit(pi[i]) <-  eta[i]
eta[i] <- inprod(beta[], X[i,])
}
#3.Probability for each variable
# E galaxies
for(l in 1:250){
logit(pgx[l])<-beta[1]+beta[2]*gx[l]
logit(pMx[l])<-beta[1]+beta[3]*Mx[l]
logit(pRx[l])<-beta[1]+beta[4]*Rx[l]
logit(psfrx[l])<-beta[1]+beta[5]*sfrx[l]
logit(pgrx[l])<-beta[1]+beta[6]*grx[l]
# S galaxies
#logit(pgxS[l])<-beta[1]+beta[2]*gx[l]+beta[7]
#logit(pMxS[l])<-beta[1]+beta[3]*Mx[l]+beta[7]
#logit(pRxS[l])<-beta[1]+beta[4]*Rx[l]+beta[7]
#logit(psfrS[l])<-beta[1]+beta[5]*sfrx[l]+beta[7]
#logit(pgrS[l])<-beta[1]+beta[6]*grx[l]+beta[7]
}
}"
params <- c("beta","pi","pgx","pMx","pRx","psfrx","pgrx")        # Monitor these parameters.
inits0  <- function () {list(beta = rnorm(K, 0, 0.01))} # A function to generat initial values for mcmc
inits1=inits0();inits2=inits0();inits3=inits0()         # Generate initial values for three chains
# Run mcmc
bin    = 10^4   # burn-in samples
ad     = 10^4   # Number of adaptive samples
s      = 3*10^4 # Number of samples for each chain
nc     = 3      # Number of mcmc
th     = 10     # Thinning value
jags.logit  <- run.jags(method="rjparallel",data = jags.data,inits = list(inits1,inits2,inits3),model=model,
n.chains = nc,adapt=ad,monitor=c(params),burnin=bin,thin=th,sample=s,summarise=FALSE,plots=FALSE)
K
### Prior Specification and Likelihood function
model<-"model{
#1. Priors
#a.Normal
#beta~dmnorm(b0,B0)
#b.Jefreys priors for sparseness
#for(j in 1:K)   {
#lnTau[j] ~ dunif(-50, 50)
#TauM[j] <- exp(lnTau[j])
#beta[j] ~ dnorm(0, TauM[j])
#Ind[j] <- step(abs(beta[j]) - 0.05)
#}
#c.LASSO
for(j in 1:K){
beta[j]~ddexp(0,tau)
}
#c1.prior for tau
tau <-pow(sdBeta,-1)
sdBeta ~ dgamma(0.01,0.01)
#2. Likelihood
for(i in 1:N){
Y[i] ~ dbern(pi[i])
logit(pi[i]) <-  eta[i]
eta[i] <- inprod(beta[], X[i,])
}
#3.Probability for each variable
# E galaxies
for(l in 1:250){
logit(pgx[l])<-beta[1]+beta[2]*gx[l]
logit(pMx[l])<-beta[1]+beta[3]*Mx[l]
logit(pRx[l])<-beta[1]+beta[4]*Rx[l]
logit(psfrx[l])<-beta[1]+beta[5]*sfrx[l]
logit(pgrx[l])<-beta[1]+beta[6]*grx[l]
# S galaxies
#logit(pgxS[l])<-beta[1]+beta[2]*gx[l]+beta[7]
#logit(pMxS[l])<-beta[1]+beta[3]*Mx[l]+beta[7]
#logit(pRxS[l])<-beta[1]+beta[4]*Rx[l]+beta[7]
#logit(psfrS[l])<-beta[1]+beta[5]*sfrx[l]+beta[7]
#logit(pgrS[l])<-beta[1]+beta[6]*grx[l]+beta[7]
}
}"
params <- c("beta","pi","pgx","pMx","pRx","psfrx","pgrx")        # Monitor these parameters.
inits0  <- function () {list(beta = rnorm(K, 0, 0.01))} # A function to generat initial values for mcmc
inits1=inits0();inits2=inits0();inits3=inits0()         # Generate initial values for three chains
# Run mcmc
bin    = 10^4   # burn-in samples
ad     = 10^4   # Number of adaptive samples
s      = 3*10^4 # Number of samples for each chain
nc     = 3      # Number of mcmc
th     = 10     # Thinning value
jags.logit  <- run.jags(method="rjparallel",data = jags.data,inits = list(inits1,inits2,inits3),model=model,
n.chains = nc,adapt=ad,monitor=c(params),burnin=bin,thin=th,sample=s,summarise=FALSE,plots=FALSE)
### Prior Specification and Likelihood function
model<-"model{
#1. Priors
#a.Normal
#beta~dmnorm(b0,B0)
#b.Jefreys priors for sparseness
#for(j in 1:K)   {
#lnTau[j] ~ dunif(-50, 50)
#TauM[j] <- exp(lnTau[j])
#beta[j] ~ dnorm(0, TauM[j])
#Ind[j] <- step(abs(beta[j]) - 0.05)
#}
#c.LASSO
for(j in 1:5){
beta[j]~ddexp(0,tau)
}
#c1.prior for tau
tau <-pow(sdBeta,-1)
sdBeta ~ dgamma(0.01,0.01)
#2. Likelihood
for(i in 1:N){
Y[i] ~ dbern(pi[i])
logit(pi[i]) <-  eta[i]
eta[i] <- inprod(beta[], X[i,])
}
#3.Probability for each variable
# E galaxies
for(l in 1:250){
logit(pgx[l])<-beta[1]+beta[2]*gx[l]
logit(pMx[l])<-beta[1]+beta[3]*Mx[l]
logit(pRx[l])<-beta[1]+beta[4]*Rx[l]
logit(psfrx[l])<-beta[1]+beta[5]*sfrx[l]
logit(pgrx[l])<-beta[1]+beta[6]*grx[l]
# S galaxies
#logit(pgxS[l])<-beta[1]+beta[2]*gx[l]+beta[7]
#logit(pMxS[l])<-beta[1]+beta[3]*Mx[l]+beta[7]
#logit(pRxS[l])<-beta[1]+beta[4]*Rx[l]+beta[7]
#logit(psfrS[l])<-beta[1]+beta[5]*sfrx[l]+beta[7]
#logit(pgrS[l])<-beta[1]+beta[6]*grx[l]+beta[7]
}
}"
params <- c("beta","pi","pgx","pMx","pRx","psfrx","pgrx")        # Monitor these parameters.
inits0  <- function () {list(beta = rnorm(K, 0, 0.01))} # A function to generat initial values for mcmc
inits1=inits0();inits2=inits0();inits3=inits0()         # Generate initial values for three chains
# Run mcmc
bin    = 10^4   # burn-in samples
ad     = 10^4   # Number of adaptive samples
s      = 3*10^4 # Number of samples for each chain
nc     = 3      # Number of mcmc
th     = 10     # Thinning value
jags.logit  <- run.jags(method="rjparallel",data = jags.data,inits = list(inits1,inits2,inits3),model=model,
n.chains = nc,adapt=ad,monitor=c(params),burnin=bin,thin=th,sample=s,summarise=FALSE,plots=FALSE)
library(arm)
library(caret)
library(pROC)
data<-read.csv("../data/sample_CRP02_sub.csv",header=TRUE,na.strings="")
data[1,]
SFR<-data$sfr_tot_p50
D1<-densityMclust(sSFR,G=2)
require(mclust)
D1<-densityMclust(sSFR,G=2)
D1<-densityMclust(SFR,G=2)
data2<-na.omit(data)
SFR<-data2$sfr_tot_p50
D1<-densityMclust(SFR,G=2)
plot(D1, what = "density", data = SFR, breaks = 25)
D1$classification
data2$sfr_tot_p50
data2    <- data2[which(data2$sfr_tot_p50>=-100),]
SFR<-data2$sfr_tot_p50
D1<-densityMclust(SFR,G=2)
plot(D1, what = "density", data = SFR, breaks = 25)
setwd("~/Dropbox/artigos/Meusartigos/IAA-WGC/Github/Logit_Mar/script")
# JAGS Code with Adaptive Shrinkage
#  Required libraries
library(rjags);library(ggmcmc);library(ggplot2);library(ggthemes);library(pander);library(Cairo);library(MASS);library(parallel)
library(scales);library(plyr);require(gdata);require(runjags);require(gdata);require(caret);require(pROC);require(plyr)
cl       <- makeCluster(3) # For parallel computing
# Read and format data
data     <- read.csv("..//data/sample_CRP02_sub.csv",header=TRUE,na.strings="")
data_cut <- data[,c("bpt","lgm_tot_p50","logM200_L","RprojLW_Rvir","sfr_tot_p50","color_gr","zoo")]
data2    <- na.omit(data_cut)
data2    <- data2[data2$lgm_tot_p50>0,]
data2    <- data2[which(data2$logM200_L>0),]
data2    <- data2[which(data2$RprojLW_Rvir>=0),]
data2    <- data2[which(data2$sfr_tot_p50>=-100),]
# Standardized variables
data2<-data.frame(bpt=data2$bpt,as.data.frame(scale(data2[,2:6])),zoo=data2$zoo)
#trainIndex <- sample(1:nrow(data2),2000)
#data3      <- data2[trainIndex,]
data3    <-data2
#data3    <- subset(data3, bpt!="LINER")    # remove Liners
data3$bpt  <- revalue(data3$bpt,c("Star Forming"="0","Composite"="0",
"LINER"="1","Seyfert/LINER"="1","Star Fo"="0",
"Seyfert"="1","BLANK"="0"))
data_n     <- data3
gam(bpt~,family="binomial")
gam(bpt~.,family="binomial")
